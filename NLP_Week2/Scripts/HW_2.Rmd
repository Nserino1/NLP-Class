---
title: "Hw_2"
author: "Nicole Serino"
date: "2026-01-28"
output:
  html_document:
    toc: true
    toc_float: true 
    toc_depth: 1
    css: !expr here::here("../StylesTemplates/NS.css")
---

```{r setup, include=F}
knitr::opts_chunk$set(fig.width=8, fig.height=5, fig.align = 'left', fig.path='Figs/', cache.path='Cache/', eval=T, echo=T, tidy=TRUE,  cache=F, message=F, warning=F, stringsAsFactors=F, yaml.eval.expr = TRUE)  

library(xfun)
pkg_attach("tidyverse", "here", "kableExtra", "RCurl", "psych", "knitr", "RColorBrewer", 'dplyr', install=T)

jamie.theme <- theme_bw() + theme(axis.line = element_line(colour = "#000000"), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.border = element_blank(), panel.background = element_blank(), legend.title= element_blank())  #custom theme ggplot2

print.me <- function(x, ...) {
if (nrow(x) > 200){
   len <- 200 
    } else {
       len <- (nrow(x))
}
   x[1:len,] %>%
   kbl(digits=2, align= 'l', booktabs=T) %>%
   kable_styling(fixed_thead = T) %>%
   kable_paper("striped", full_width = T, html_font = "Helvetica", font_size = 12) %>%
   row_spec(0, color = "white", background = "#5b705f", font_size = 12) %>%
   scroll_box(width = "700px", height = "500px") %>%
   asis_output()
}

registerS3method("knit_print", "data.frame", print.me)
#to_R <- read.csv(here("data", "MyRaw.txt")) ---- using 'here' to read in data
```
Load Packages
```{r}
rm(list = ls())
library(readr)
library(tidyr)
library(tidyverse)
library(tidytext)

```
 
 # 1. Read 'sticks_messy.txt' into R
```{r}
#read in my txt file as a string
text <- read_file("/Users/tut38747/Library/CloudStorage/OneDrive-TempleUniversity/Serino_RData/NLP-Class/NLP_Week2/Data/sticks_messy.txt")
```
   
    
# 2. Create a cleaning function with at least three chained procedures
```{r}
#create my cleaning function
clean <- function(x) {

#make all lowercase with tolower
  x <- tolower(x)
#remove any numbers from text
  x <- gsub("[[:digit:]]", " ", x)
  
#remove all punctuation
  x <- gsub("[[:punct:]]", " ", x)

#remove any single character tht isnt "a" ot "i". How: Remove any character that isnt "a" or "i" that is a singleton becuase it exists between two whitespaces.
  x <- gsub("\\b[^ai]\\b", " ", x)

#remove extra spaces by removing whitespace characters that occur more than once in a row. 
  x <- gsub("\\s+", " ", x)
  
#SHOW ME
  print(x)
}

```

# 3. Clean the text file using your homemade cleaning function
```{r}
#Use my cleaning function on my data
clean_txt <-clean(text)
```

# 4. Split the text file into a one-word-per row format
```{r}
#Split string and unlist so it is a vectr. Store each word in a row of a tibble.
words <- tibble(unlist(strsplit(clean_txt, " "))) 
words
```

# 5. Count words in the story
```{r}
#Count words in tibble by counting rows
type <- nrow(words)
type
```

# 6. Compute type token ratio
```{r}
#Make a new tibble of only unique words from "words". One word per row
unique <- tibble(unique(unlist(words)))
unique

#Count how many unique words there are by calculating the # of rows un my unique word tibble.
token <- nrow(unique)
token

#Calculate token- type ratio: Total unique words (token) over total number of words in text.
TTR <- (token/type)
TTR
```
